{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce192710-a2c3-4c45-b60b-66c50a1e2bc9",
   "metadata": {},
   "source": [
    "# Creating a fully connected neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d597bd1-fb92-4601-9092-eea1fe242619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from IPython.display import Image\n",
    "from sklearn.model_selection import train_test_split  # For splitting data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06ec2fc5-d64e-4ae3-a2a5-4d9a33571b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:4\n"
     ]
    }
   ],
   "source": [
    "# Define the device (use GPU if available)\n",
    "device = torch.device('cuda:4' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec193063-bcbd-424f-995c-2bd0b50eb924",
   "metadata": {},
   "source": [
    "Network specs for the layers to make easy edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a99b16a-4b4d-4d69-baa1-23b17171f30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185015, 32768)\n",
      "(185015,)\n",
      "Number of classes: 20\n"
     ]
    }
   ],
   "source": [
    "file_name = \"256_AI_And_Classes_features.npz\"\n",
    "\n",
    "data = np.load(f\"Features/{file_name}\")\n",
    "features = data['features']\n",
    "labels = data['labels']\n",
    "\n",
    "X = features\n",
    "y = labels\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Get the number of unique classes\n",
    "num_classes = len(np.unique(y))\n",
    "print(\"Number of classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9627c3ca-4396-485e-8222-4ca69d4a22df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32768, 16384, 8192, 4096, 2048, 1024, 512, 20]\n"
     ]
    }
   ],
   "source": [
    "# Network Specs\n",
    "input_size = X.shape[1]  # image data size\n",
    "output_size = num_classes\n",
    "layer_sizes = [input_size, input_size//2, input_size//4, input_size // 8, input_size // 16, input_size // 32, input_size // 64,output_size]\n",
    "print(layer_sizes)\n",
    "# Training parameters\n",
    "batch_size = 512\n",
    "epochs = 50\n",
    "lrate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0a60335-e086-47ab-a813-10115d3b1979",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        # Create a list to hold the layers\n",
    "        layers = []\n",
    "\n",
    "        # Hidden layers\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            layers.append(nn.Linear(layer_sizes[i], layer_sizes[i + 1]))\n",
    "            if i < len(layer_sizes) - 2:  # Don't add ReLU after the last hidden layer\n",
    "                layers.append(nn.ReLU())\n",
    "        \n",
    "        # Combine all layers into a Sequential module\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, input_size)\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb5bef5f-2b15-40e4-9eda-4818a620e991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaders created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Split into testing and training data\n",
    "X, X_test, y, y_test = train_test_split(features, labels, test_size=0.2, random_state=0)\n",
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)  # Ensure dtype is appropriate for your data\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)  # Ensure dtype is appropriate for your data\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create PyTorch Datasets and DataLoaders for training\n",
    "train_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)  # Do the same for your test data\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print('Data loaders created successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf30d1d5-01f0-401f-94c6-2a692cfd0994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=32768, out_features=16384, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=16384, out_features=8192, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=8192, out_features=4096, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=512, out_features=20, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#instantiate the model, while also defining loss function & optimizer\n",
    "model = NeuralNet().to(device)\n",
    "print(model)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0a250a-e5d0-4cbf-967b-3e389749d034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 34512.7619\n",
      "Epoch [2/50], Loss: 11.5374\n",
      "Epoch [3/50], Loss: 2.9327\n",
      "Epoch [4/50], Loss: 2.9324\n",
      "Epoch [5/50], Loss: 2.9327\n",
      "Epoch [6/50], Loss: 2.9328\n",
      "Epoch [7/50], Loss: 2.9328\n",
      "Epoch [8/50], Loss: 2.9327\n",
      "Epoch [9/50], Loss: 2.9327\n",
      "Epoch [10/50], Loss: 2.9330\n",
      "Epoch [11/50], Loss: 2.9330\n",
      "Epoch [12/50], Loss: 2.9328\n",
      "Epoch [13/50], Loss: 2.9326\n",
      "Epoch [14/50], Loss: 2.9328\n",
      "Epoch [15/50], Loss: 2.9327\n",
      "Epoch [16/50], Loss: 2.9328\n",
      "Epoch [17/50], Loss: 2.9328\n",
      "Epoch [18/50], Loss: 2.9327\n",
      "Epoch [19/50], Loss: 2.9327\n",
      "Epoch [20/50], Loss: 2.9327\n",
      "Epoch [21/50], Loss: 2.9329\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=epochs):\n",
    "    time_start = time()\n",
    "    model.train()  # Set model to training mode\n",
    "    epoch_losses = []  # List to store average loss for each epoch\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for features, labels in train_loader:\n",
    "            labels = labels.type(torch.LongTensor)\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(features)\n",
    "            outputs = outputs.reshape(outputs.size(0), -1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()           # reset gradient\n",
    "            loss.backward()                 # automated backwards pass\n",
    "            optimizer.step()                # take a step\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        epoch_losses.append(avg_loss)  # Store the average loss\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "    time_stop = time()\n",
    "    time_elapsed = time_stop - time_start\n",
    "    print(f'Elapsed time {round(time_elapsed, 1)} sec.')\n",
    "\n",
    "    # Plotting the loss over epochs\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, epochs + 1), epoch_losses, marker='o')\n",
    "    plt.title('Training Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.xticks(range(1, epochs + 1))\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Call the training function\n",
    "train_model(model, train_loader, criterion, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae68245b-732f-47da-a94c-e16a33e0984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing loop\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            outputs = outputs.reshape(outputs.size(0), -1)\n",
    "            _, predicted = torch.max(outputs.data, 1)         # predicted = index of maximum probability\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy of the model on the test dataset: {accuracy:.2f}%')\n",
    "\n",
    "test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558c2c74-c4e1-47f8-b4dd-e8c41690430f",
   "metadata": {},
   "source": [
    "| Device | Dataset                   | Num Images | Image Size | Epochs | Batch Size | Accuracy (%) | Time (sec) |\n",
    "|:-------|:--------------------------|:-----------|:-----------|:-------|:-----------|:-------------|:-----------|\n",
    "| GPU    | Small_Just_Classes_Dataset| 1000       | 256x256    | 15     | 512        | 57.00        | 3.4        | \n",
    "| GPU    | AI_And_Classes            | 185015     | 256x256    | 15     | 512        | 74.42        | 660.8      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acddcc2a-196e-498d-9dc0-501273395c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

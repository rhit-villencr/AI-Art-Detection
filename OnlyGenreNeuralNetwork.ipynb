{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e451f074-27a0-4040-a18f-f3d5006dfd45",
   "metadata": {},
   "source": [
    "Neural Network for Classifying only Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c52752-fce4-4ddc-a6c6-9f51ec771cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from IPython.display import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import subprocess\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34fa9a3-f418-4683-a3b8-ce85fb38ad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of a GPU\n",
    "gpu_num = -1\n",
    "\n",
    "#Loop through avtive GPUs to check for free GPUs\n",
    "for i in range(7, 0, -1):\n",
    "    print(i)\n",
    "    result = subprocess.run(f\"nvidia-smi -i {i}\", shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    if \"No running processes found\" in result.stdout:\n",
    "        gpu_num = i\n",
    "        break\n",
    "\n",
    "#If no GPU found, only run nvidia-smi once\n",
    "first_attempt = True\n",
    "\n",
    "#Ensure correct input\n",
    "while 0 > gpu_num or gpu_num > 7:\n",
    "    #Run nvidia-smi command\n",
    "    if first_attempt:\n",
    "        !nvidia-smi\n",
    "        first_attempt = False\n",
    "\n",
    "    #Type checking for int between 0 and 7\n",
    "    try:\n",
    "        gpu_num = int(input(\"No Free GPUs Found, manually enter GPU index (0-7): \"))\n",
    "        if 0 <= gpu_num <= 7:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Error: GPU index must be between 0 and 7.\")\n",
    "    except ValueError:\n",
    "        print(\"Error: Please enter a valid integer.\")\n",
    "\n",
    "#Declare device as free device found above  \n",
    "device = torch.device(f'cuda:{gpu_num}' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2cd906-4b69-40e4-ad38-ac271e25a8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.fc1=nn.Linear(input_size, input_size*2)\n",
    "        self.fc2=nn.Linear(input_size*2, input_size)\n",
    "        self.outputLayer=nn.Linear(input_size, output_size)\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.view(-1, self.input_size)\n",
    "        x=self.fc1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.fc2(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.outputLayer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc5d201-f2ae-4dae-aa96-442bc1bbeb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs, patience):\n",
    "    time_start = time()\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    final_epoch = -1\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for features, labels in train_loader:\n",
    "            labels = labels.type(torch.LongTensor)\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(features)\n",
    "            outputs = outputs.reshape(outputs.size(0), -1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()           # reset gradient\n",
    "            loss.backward()                 # automated backwards pass\n",
    "            optimizer.step()                # take a step\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        epoch_losses.append(avg_loss)  # Store the average loss\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for features, labels in val_loader:\n",
    "                labels = labels.type(torch.LongTensor)\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "                outputs = model(features)\n",
    "                outputs = outputs.reshape(outputs.size(0), -1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')\n",
    "        final_epoch = epoch+2\n",
    "\n",
    "        # Early stopping check\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(colored(f'Early stopping triggered after {epoch+1} epochs.', 'red'))\n",
    "                break\n",
    "\n",
    "    # Load the best model state\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "    time_stop = time()\n",
    "    time_elapsed = time_stop - time_start\n",
    "    print(f'Elapsed time {round(time_elapsed, 1)} sec.')\n",
    "\n",
    "    # Plotting the loss over epochs\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, final_epoch), epoch_losses, marker='o')\n",
    "    plt.title('Training Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.xticks(range(1, epochs + 1))\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting the validation error over epochs\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, final_epoch), val_losses, marker='o')\n",
    "    plt.title('Validation Error over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation Error')\n",
    "    plt.xticks(range(1, epochs + 1))\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f9d525-acae-4b7f-82b0-0a639b661d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing loop with confusion matrix\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            outputs = outputs.reshape(outputs.size(0), -1)\n",
    "            _, predicted = torch.max(outputs.data, 1)  # predicted = index of maximum probability\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Append true and predicted labels for confusion matrix\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Calculate and print accuracy\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy of the model on the test dataset: {accuracy:.2f}%')\n",
    "\n",
    "    # Generate and plot confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(20, 14))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', linewidths=0.1, linecolor='Blue')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b949078c-8a81-4202-9ef5-aaed45598e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModel(file_name, batch_size=512, epochs=25, lrate=0.01, patience=16):\n",
    "    data = np.load(f\"Features/{file_name}\")\n",
    "    features = data['features']\n",
    "    labels = data['labels']\n",
    "    remove_labels = list(range(10))\n",
    "\n",
    "    X = features\n",
    "    y = labels\n",
    "    \n",
    "    print(colored(\"Device:\",\"blue\"))\n",
    "    print(f\"\\t{device}\\n\")\n",
    "    \n",
    "    print(colored(\"Feature Size:\",\"blue\"))\n",
    "    print(f\"\\t{X.shape[1]}\\n\")\n",
    "\n",
    "    print(colored(\"Number of Images:\",\"blue\"))\n",
    "    print(f\"\\t{X.shape[0]}\\n\")\n",
    "    \n",
    "    # Get the number of unique classes\n",
    "    num_classes = len(np.unique(y))\n",
    "    print(colored(\"Number of classes:\", \"blue\"))\n",
    "    print(f\"\\t{num_classes}\\n\")\n",
    "\n",
    "    # Network Specs\n",
    "    input_size = X.shape[1]  # image data size\n",
    "    output_size = num_classes\n",
    "\n",
    "    #instantiate the model, while also defining loss function & optimizer\n",
    "    model = NeuralNet(input_size=input_size, output_size=output_size).to(device)\n",
    "    print(colored(\"Neural Net Definition:\", \"blue\"))\n",
    "    print(f\"{model}\\n\")\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lrate)\n",
    "\n",
    "    # Split into testing and training data\n",
    "    X, X_test, y, y_test = train_test_split(features, labels, test_size=0.2, random_state=0)\n",
    "    \n",
    "    # Further split the training data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "    \n",
    "    X_tensor = torch.tensor(X_train, dtype=torch.float32)  # Ensure dtype is appropriate for your data\n",
    "    y_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "    \n",
    "    # Create PyTorch Datasets and DataLoaders for training, test, and validation\n",
    "    train_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    \n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    print(colored(\"Begin Model Training:\", \"blue\"))\n",
    "    \n",
    "    train_model(model, train_loader, val_loader, criterion, optimizer, epochs=epochs, patience=patience)\n",
    "    test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44506d9-dc0b-4dfb-8f66-0284d251ff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add file of extracted features\n",
    "runModel(file_name='', batch_size=500, epochs=50, lrate=0.001, patience=7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "project_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
